{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n13NcYoBTmhw",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAieTO2Ya0BD",
        "colab_type": "text"
      },
      "source": [
        "### Load and clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "import requests\n",
        "\n",
        "r = requests.get('https://www.gutenberg.org/files/100/100-0.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ejq2k-p9f7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7e6e912b-9938-4439-da23-2f17577b5541"
      },
      "source": [
        "text = r.content.decode('utf-8')\n",
        "text[:500]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeff\\r\\nProject Gutenberg’s The Complete Works of William Shakespeare, by William\\r\\nShakespeare\\r\\n\\r\\nThis eBook is for the use of anyone anywhere in the United States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever.  You may copy it, give it away or re-use it under the terms\\r\\nof the Project Gutenberg License included with this eBook or online at\\r\\nwww.gutenberg.org.  If you are not located in the United States, you’ll\\r\\nhave to check the laws of the country where '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xyQvVXh-EZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8aec3bdc-b799-48f7-ba3e-76c29ebd36ea"
      },
      "source": [
        "# remove some of the extra characters\n",
        "text = text.replace('\\r', '')\n",
        "text[:500]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeff\\nProject Gutenberg’s The Complete Works of William Shakespeare, by William\\nShakespeare\\n\\nThis eBook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever.  You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this eBook or online at\\nwww.gutenberg.org.  If you are not located in the United States, you’ll\\nhave to check the laws of the country where you are l'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNSIn1CV-uhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "59b86670-7699-42bb-e155-833619b3929a"
      },
      "source": [
        "# remove the preface so we have just Shakespear's works (keeping table of contents for now)\n",
        "text = text[827:]\n",
        "text[:500]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n               THE SONNETS\\n\\n               ALL’S WELL THAT ENDS WELL\\n\\n               THE TRAGEDY OF ANTONY AND CLEOPATRA\\n\\n               AS YOU LIKE IT\\n\\n               THE COMEDY OF ERRORS\\n\\n               THE TRAGEDY OF CORIOLANUS\\n\\n               CYMBELINE\\n\\n               THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\\n\\n               THE FIRST PART OF KING HENRY THE FOURTH\\n\\n               THE SECOND PART OF KING '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwS-6rwo93Fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab7e021d-47f3-44bc-d5f2-9d22bcb676b1"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5572325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCf8nidfa43I",
        "colab_type": "text"
      },
      "source": [
        "### Encode the data as sequences of characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voRtiTqxALpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDcrKiIR_6yI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b7f8db5-b262-4f64-e6c6-63702b8116ab"
      },
      "source": [
        "# break the text into character sequences\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is maxlen chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1114457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpZ9prW5AYQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8cd617ce-438c-4263-b8d4-2328ff76a6e2"
      },
      "source": [
        "# Create X & y\n",
        "import numpy as np\n",
        "\n",
        "X = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        X[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1114457, 40, 105)\n",
            "(1114457, 105)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y_K5Q4HbAKs",
        "colab_type": "text"
      },
      "source": [
        "### Define functions for previewing predictions during the training\n",
        "\n",
        "From the lecture notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3aREr9eBnLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg4X0I1xBpDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "import random\n",
        "import sys\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    # Only print a preview every 5 epochs\n",
        "    if (epoch % 5 == 0):\n",
        "      print()\n",
        "      print('----- Generating text after Epoch: %d' % epoch)\n",
        "      \n",
        "      start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "      \n",
        "      generated = ''\n",
        "      \n",
        "      sentence = text[start_index: start_index + maxlen]\n",
        "      generated += sentence\n",
        "      \n",
        "      print('----- Generating with seed: \"' + sentence + '\"')\n",
        "      sys.stdout.write(generated)\n",
        "      \n",
        "      for i in range(400):\n",
        "          x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "          for t, char in enumerate(sentence):\n",
        "              x_pred[0, t, char_int[char]] = 1\n",
        "              \n",
        "          preds = model.predict(x_pred, verbose=0)[0]\n",
        "          next_index = sample(preds)\n",
        "          next_char = int_char[next_index]\n",
        "          \n",
        "          sentence = sentence[1:] + next_char\n",
        "          \n",
        "          sys.stdout.write(next_char)\n",
        "          sys.stdout.flush()\n",
        "      print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPyQIog-bH8x",
        "colab_type": "text"
      },
      "source": [
        "### Build and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwATCgC5BYUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the LSTM model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUWm8Ca9By27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "023c7795-fd8d-4b29-bf45-317703e9c911"
      },
      "source": [
        "# fit the model\n",
        "model.fit(X, y,\n",
        "          batch_size=32,\n",
        "          epochs=50,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "34826/34827 [============================>.] - ETA: 0s - loss: 2.0075\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"d we create, in absence of ourself,\n",
            "    \"\n",
            "d we create, in absence of ourself,\n",
            "    These bett!\n",
            "  KINE. There some, the Pisius\n",
            "    Ale untidcest givenn that it swarniar,\n",
            "    None.\n",
            "\n",
            "ALMICO.\n",
            "      Lay, I how discher's, thish dimenor my buss\n",
            "    And surd anflesh, not lood than her denty,\n",
            "Th’e wet not delisg toomancy crick a bul\n",
            "    Theirath affeny wasted the Casbant,\n",
            "    Lexter couss as dy coblougs the tongcted.\n",
            "\n",
            "THUST. Yis come sucp hem blessioned raice\n",
            "the dight.\n",
            "\n",
            "PARIOP.\n",
            "What hav\n",
            "34827/34827 [==============================] - 196s 6ms/step - loss: 2.0074\n",
            "Epoch 2/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.7040\n",
            "Epoch 3/50\n",
            "34827/34827 [==============================] - 184s 5ms/step - loss: 1.6050\n",
            "Epoch 4/50\n",
            "34827/34827 [==============================] - 183s 5ms/step - loss: 1.5509\n",
            "Epoch 5/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.5158\n",
            "Epoch 6/50\n",
            "34826/34827 [============================>.] - ETA: 0s - loss: 1.4913\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"y Council,\n",
            "    As more at large your Gra\"\n",
            "y Council,\n",
            "    As more at large your Grame with yellows it,\n",
            "Nock more by messen conjudge rateer\n",
            "would my instrome.\n",
            "\n",
            "ORBRICONT.\n",
            "What do you not sair, did we ferst dless’d,\n",
            "    chose makew to boft the man in Senn a diver\n",
            "Hurtel coits over Boingly Cousied for you.\n",
            "  SPBETESS. What, good fire of your bearth and acquay.\n",
            "\n",
            "Hathing with astressing and words in\n",
            "What I corvelt, it be thee would I will inly\n",
            "To please of the gance this, no morish’d\n",
            "34827/34827 [==============================] - 196s 6ms/step - loss: 1.4913\n",
            "Epoch 7/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.4727\n",
            "Epoch 8/50\n",
            "34827/34827 [==============================] - 181s 5ms/step - loss: 1.4575\n",
            "Epoch 9/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.4454\n",
            "Epoch 10/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.4352\n",
            "Epoch 11/50\n",
            "34824/34827 [============================>.] - ETA: 0s - loss: 1.4263\n",
            "----- Generating text after Epoch: 10\n",
            "----- Generating with seed: \"not change my horse with any that\n",
            "treads\"\n",
            "not change my horse with any that\n",
            "treadst so music, with it paisons my devine!\n",
            "We to trueth, and to brooketszunest.\n",
            "\n",
            "LEAR.\n",
            "I’ll be, you are sicks son with an Exbage\n",
            "Bound. Alas, that Look Pleneant, the Tram of Francis,\n",
            "    Beside hands, is sleep, in hard as whore new,\n",
            "With recutest of alary aget by yours. In the lows you\n",
            "Doth glorious without ground.\n",
            "  TRANIOLY. Sir Soldier that I complest I know. He biding\n",
            "no you for kep and the mother\n",
            "34827/34827 [==============================] - 195s 6ms/step - loss: 1.4262\n",
            "Epoch 12/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.4170\n",
            "Epoch 13/50\n",
            "34827/34827 [==============================] - 184s 5ms/step - loss: 1.4135\n",
            "Epoch 14/50\n",
            "34827/34827 [==============================] - 185s 5ms/step - loss: 1.6917\n",
            "Epoch 15/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 2.0594\n",
            "Epoch 16/50\n",
            "34824/34827 [============================>.] - ETA: 0s - loss: 1.5918\n",
            "----- Generating text after Epoch: 15\n",
            "----- Generating with seed: \"lmes, or put to sea,\n",
            "Or tell of Babes br\"\n",
            "lmes, or put to sea,\n",
            "Or tell of Babes briees patchances, which I live the ill.\n",
            "  That is nove knights, grow mine eye, told upon, butbleing and twop'd, eliege how apppisiafifis cans!\n",
            "  ROSALINCE. So sure not every to-derire.\n",
            "  TADY. Nay, ye seree. Thou speaking says full,\n",
            "    Then gom in Beetras them then, with his raillow conscued,\n",
            "Stafulo cousced-day of the humbey imids\n",
            "    Of your beautio supplayed ome stran\n",
            "figuring creaps to not alo\n",
            "34827/34827 [==============================] - 196s 6ms/step - loss: 1.5918\n",
            "Epoch 17/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.4627\n",
            "Epoch 18/50\n",
            "34827/34827 [==============================] - 183s 5ms/step - loss: 1.4112\n",
            "Epoch 19/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.3999\n",
            "Epoch 20/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.3935\n",
            "Epoch 21/50\n",
            "34826/34827 [============================>.] - ETA: 0s - loss: 1.3882\n",
            "----- Generating text after Epoch: 20\n",
            "----- Generating with seed: \"common men.\n",
            "\n",
            "KING HENRY.\n",
            "This note doth \"\n",
            "common men.\n",
            "\n",
            "KING HENRY.\n",
            "This note doth standes it your behord,\n",
            "I told bent of you lies eye errasts tormers ingell?\n",
            "\n",
            " MENENAUS.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "That’s most certain.\n",
            "\n",
            "FIRST POMANDO.\n",
            "Our one them.\n",
            "\n",
            "DOCTOR.\n",
            "My, what, yet that, you told, a parah!\n",
            "\n",
            "            Eneen\n",
            "  ANGELDOUS OS] Grace of they will scorn; for sill stip; in Vief,\n",
            "    Where his excupser service, grow on state,\n",
            "    Tad to liegnisRy and one farber'd to deft.\n",
            "  SUFFOLK. To in home is\n",
            "    King,\n",
            "34827/34827 [==============================] - 195s 6ms/step - loss: 1.3882\n",
            "Epoch 22/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3836\n",
            "Epoch 23/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3800\n",
            "Epoch 24/50\n",
            "34827/34827 [==============================] - 181s 5ms/step - loss: 1.3767\n",
            "Epoch 25/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3738\n",
            "Epoch 26/50\n",
            "34820/34827 [============================>.] - ETA: 0s - loss: 1.3711\n",
            "----- Generating text after Epoch: 25\n",
            "----- Generating with seed: \" shore to shore, and left me breath\n",
            "Noth\"\n",
            " shore to shore, and left me breath\n",
            "Noth make my sake, this soad the assoance stain by\n",
            "From desire to have mistatim! I do how five a gracifish art yet?\n",
            "    What kissuaus we that I give me tainted.\n",
            "  MURDEMAR. They inseep to divine?\n",
            "  PHOTER.\n",
            "               The Capultudy, MAERON\n",
            "    Clarence you can from the worfine, that they\n",
            "ware my further estriction to hear recovied\n",
            "    or calleth best starding leds. ansterers was o't, and what be gl\n",
            "34827/34827 [==============================] - 193s 6ms/step - loss: 1.3711\n",
            "Epoch 27/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3690\n",
            "Epoch 28/50\n",
            "34827/34827 [==============================] - 181s 5ms/step - loss: 1.3662\n",
            "Epoch 29/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3650\n",
            "Epoch 30/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3630\n",
            "Epoch 31/50\n",
            "34826/34827 [============================>.] - ETA: 0s - loss: 1.3613\n",
            "----- Generating text after Epoch: 30\n",
            "----- Generating with seed: \"ntaged, and\n",
            "    the corrupt deputy scale\"\n",
            "ntaged, and\n",
            "    the corrupt deputy scale.\n",
            "  MENENIUS. What's than you tell him clother, sir, Troes never for\n",
            "    rome all, for that a part a tending th'\n",
            "    tender we say ave dance;\n",
            "    With blush burn. Why, quoth the world sor fools to\n",
            "    well; nor that Lucius here can be not such and touch\n",
            "More seased ain makes a se.'NW thee with less part out, boose son that King of thy\n",
            "shall all tonight her?\n",
            "She I am so: I do! a less thy than the b\n",
            "34827/34827 [==============================] - 195s 6ms/step - loss: 1.3613\n",
            "Epoch 32/50\n",
            "34827/34827 [==============================] - 181s 5ms/step - loss: 1.3596\n",
            "Epoch 33/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3580\n",
            "Epoch 34/50\n",
            "34827/34827 [==============================] - 178s 5ms/step - loss: 1.3568\n",
            "Epoch 35/50\n",
            "34827/34827 [==============================] - 181s 5ms/step - loss: 1.3557\n",
            "Epoch 36/50\n",
            "34826/34827 [============================>.] - ETA: 0s - loss: 1.3543\n",
            "----- Generating text after Epoch: 35\n",
            "----- Generating with seed: \"nk, Timon.\n",
            "  SECOND LORD. Joy had the li\"\n",
            "nk, Timon.\n",
            "  SECOND LORD. Joy had the life in head?\n",
            "  SPEED. Gave, my Hign alonion; I'll bid not?\n",
            "  CATES. Farthow, whom Ay, huge them, in his ribblipfs so thine\n",
            "    The grassing ageith's too blood a pride man\n",
            "    My groanst howeden. No, I am tocking'd.\n",
            "  HAST. Exeunt LADY\n",
            "\n",
            "\n",
            "\n",
            "ACT IV\n",
            "\n",
            "SCENE III. corners\n",
            "\n",
            " Enter Fenelate would that faith having. I'll you alter, and right!\n",
            "  KATHARINE. Thou art but the world should sweet far ittle forefore\n",
            "34827/34827 [==============================] - 194s 6ms/step - loss: 1.3543\n",
            "Epoch 37/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.3527\n",
            "Epoch 38/50\n",
            "34827/34827 [==============================] - 181s 5ms/step - loss: 1.3522\n",
            "Epoch 39/50\n",
            "34827/34827 [==============================] - 181s 5ms/step - loss: 1.3509\n",
            "Epoch 40/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.3498\n",
            "Epoch 41/50\n",
            "34826/34827 [============================>.] - ETA: 0s - loss: 1.3489\n",
            "----- Generating text after Epoch: 40\n",
            "----- Generating with seed: \"O. Well; come to me to-morrow.\n",
            "  LUCIO. \"\n",
            "O. Well; come to me to-morrow.\n",
            "  LUCIO. Will, give't, you will?\n",
            "  TITUS. Melany!\n",
            "  JULIA. My lord, is Somerset, sleep where I send it.\n",
            "\n",
            "AEDMONDRANE.\n",
            "Ay, yes all his whills to be a tende,\n",
            "And I heard yeeds of the vow.\n",
            "\n",
            " Enter Duke of O crick, Clower.\n",
            "\n",
            "MENELAUS.\n",
            "[Cry office; for how I do foul under me enough ear;\n",
            "    There's not he meet their hence and thought upon your shadow;\n",
            "    As thy comfortsious my tolmeth and require\n",
            "    And there \n",
            "34827/34827 [==============================] - 195s 6ms/step - loss: 1.3490\n",
            "Epoch 42/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.3478\n",
            "Epoch 43/50\n",
            "34827/34827 [==============================] - 181s 5ms/step - loss: 1.3471\n",
            "Epoch 44/50\n",
            "34827/34827 [==============================] - 182s 5ms/step - loss: 1.3460\n",
            "Epoch 45/50\n",
            "34827/34827 [==============================] - 183s 5ms/step - loss: 1.3459\n",
            "Epoch 46/50\n",
            "34818/34827 [============================>.] - ETA: 0s - loss: 1.3446\n",
            "----- Generating text after Epoch: 45\n",
            "----- Generating with seed: \"ter\n",
            "Than in the note of judgement; and w\"\n",
            "ter\n",
            "Than in the note of judgement; and which showers lose walked\n",
            "Cyrculvous brecine for feasting had the England?\n",
            "  POMTEYNE. O, coming you will her.                  Exeug SELATAMO wracture hath Hontuse\n",
            "ULoo field to France.\n",
            "\n",
            "PERICLES.\n",
            "If Geem I a fitre being all.\n",
            "\n",
            "LUCENTIO.\n",
            "I might be their engions of from his\n",
            "Gract to diathregui’d to strange. Have I laid me\n",
            "That intermiging sac those poor and tears. Come\n",
            "    Whose thing wan before, a\n",
            "34827/34827 [==============================] - 193s 6ms/step - loss: 1.3446\n",
            "Epoch 47/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3437\n",
            "Epoch 48/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3404\n",
            "Epoch 49/50\n",
            "34827/34827 [==============================] - 178s 5ms/step - loss: 1.3426\n",
            "Epoch 50/50\n",
            "34827/34827 [==============================] - 180s 5ms/step - loss: 1.3422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5c4a1cb5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1ccM_9DbKst",
        "colab_type": "text"
      },
      "source": [
        "### Generate a single prediction at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gUltwZsbfb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# separating some code from the on_epoch_end function earlier\n",
        "def predict(prediction_model, length=400):\n",
        "  \"\"\" \n",
        "  returns a random prediction from the model\n",
        "  \n",
        "  param length: the number of characters to generate\n",
        "  \"\"\"\n",
        "\n",
        "  start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "  seed = text[start_index: start_index + maxlen]\n",
        "  generated = seed\n",
        "  \n",
        "  print('----- Generating with seed: \"' + seed + '\"\\n')\n",
        "  \n",
        "  for i in range(length):\n",
        "    # encode the seed for the model\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(seed):\n",
        "      x_pred[0, t, char_int[char]] = 1\n",
        "    \n",
        "    # make a prediction\n",
        "    preds = prediction_model.predict(x_pred, verbose=0)[0]\n",
        "\n",
        "    # convert back from index to character\n",
        "    next_index = sample(preds)\n",
        "    next_char = int_char[next_index]\n",
        "    \n",
        "    # shift seed for the next prediction\n",
        "    seed = seed[1:] + next_char\n",
        "\n",
        "    # save the generated character to the output\n",
        "    generated += next_char\n",
        "\n",
        "  return generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZb01FxlqNrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "      \n",
        "generated = ''\n",
        "\n",
        "sentence = text[start_index: start_index + maxlen]\n",
        "generated += sentence\n",
        "\n",
        "print('----- Generating with seed: \"' + sentence + '\"')\n",
        "sys.stdout.write(generated)\n",
        "\n",
        "for i in range(400):\n",
        "  x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "  for t, char in enumerate(sentence):\n",
        "    x_pred[0, t, char_int[char]] = 1\n",
        "      \n",
        "  preds = model.predict(x_pred, verbose=0)[0]\n",
        "  next_index = sample(preds)\n",
        "  next_char = int_char[next_index]\n",
        "  \n",
        "  sentence = sentence[1:] + next_char\n",
        "  \n",
        "  sys.stdout.write(next_char)\n",
        "  sys.stdout.flush()\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCCXj1M_emuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "2c86e293-c9f1-4b24-c3c4-2ecca3ed01c7"
      },
      "source": [
        "print(predict(model, length=500))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Generating with seed: \"oud.\n",
            "\n",
            "DIOMEDES.\n",
            "Or covetous of praise.\n",
            "\n",
            "\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "oud.\n",
            "\n",
            "DIOMEDES.\n",
            "Or covetous of praise.\n",
            "\n",
            "LEONTES.\n",
            "Yes, death, late.\n",
            "\n",
            "CLOWN.\n",
            "Is this capbray.\n",
            "\n",
            "GOW, Godsan belieun\n",
            "\n",
            "Abate stareter’ told of uniters of me that he is\n",
            "      the world to had this no one. Let station is nothing.\n",
            "\n",
            "           Enter PAGE. Not forgen your part you gone?\n",
            "  OLIVER. Look I buke were penarition\n",
            "    To deny lustiess and will of schoducude\n",
            "Do us that answer and that must your form wound late,\n",
            "Make so much hands pains to peacent vown appare,\n",
            "In shills and to ridest nor thought.\n",
            "You do come to yet. Making Claudio thy\n",
            "f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qVlc0g_bfq1",
        "colab_type": "text"
      },
      "source": [
        "### Save and download model so I can use it again without re-training\n",
        "\n",
        "https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeu6Yceqbq8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fde979fe-1319-4c6c-c0f0-bb1cb95bdb35"
      },
      "source": [
        "!pip install h5py"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XOmCsmgdsVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model to a file\n",
        "model.save(\"shakespear_character_model.h5\")\n",
        "\n",
        "# Download from colab to my local machine, for later\n",
        "from google.colab import files\n",
        "files.download('shakespear_character_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89coUZ76blnC",
        "colab_type": "text"
      },
      "source": [
        "### How to load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-62eY7tbqm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# load model\n",
        "loaded_model = load_model('shakespear_character_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA9A8v3CfBo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "58cfaa8b-f45a-4030-a413-beacc5042bca"
      },
      "source": [
        "# demonstrate that the loaded model can make the same predictions\n",
        "print(predict(loaded_model, length=500))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Generating with seed: \"w,\n",
            "    It is not Caesar's natural vice t\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "w,\n",
            "    It is not Caesar's natural vice this,\n",
            "'Tile there in abavited by Englas;—the Iholl scarce he.\n",
            "    Where's Sir John Adrennise, and too fare!\n",
            "    Where's here? That our errement the contenc'd.\n",
            "    Their grace of all the throctar'd of sobers\n",
            "    I know joy, with your love, depalling; and if thy church pray France,\n",
            "To his works may back Pelse in to poor, there must be bringned\n",
            "Will with you chance in all titles in outours this gift\n",
            "Than as nestress thing) hor Herefies\n",
            "Convey’s frrest thee let you my soldier.\n",
            "\n",
            "CINNA.\n",
            "Have my brother\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7zqXYnAjNuj",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goal: tokenize each word and train a model with words instead of characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7DRdf5Fz2J5",
        "colab_type": "text"
      },
      "source": [
        "### Remove license at the end\n",
        "\n",
        "I realized that the text had a license at the end that I hadn't removed before.  I'll remove that now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kn657-D0AsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "82b40011-1ff1-4099-83a6-c70fc6857d67"
      },
      "source": [
        "text[-21100:]"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n* CONTENT NOTE (added in 2017) *\\n\\nThis Project Gutenberg eBook was originally marked as having a copyright.\\nHowever, Project Gutenberg now believes that the eBook\\'s contents does\\nnot actually have a copyright.\\n\\nThis is based on current understanding of copyright law, in which\\n\"authorship\" is required to obtain a copyright.  See the \"No Sweat of\\nthe Brow Copyright\" how-to at www.gutenberg.org for more details on\\nthis.\\n\\nThis eBook was provided to Project Gutenberg by the World Library\\nInc., which published a series of CDROM products called \"Library of\\nthe Future\" from approximately 1991-1994.  Copyright registration\\nrecords filed with the U.S. Copyright Office at the time record a\\ncopyright for \"New Matter: compilation, arr., revisions and additions.\"\\n\\nWithin the INDIVIDUAL eBooks on the CDROM, this copyright statement\\nappears: \"Electronically Enhanced Text Copyright 1991 World Library,\\nInc.\"\\n\\nThere is no indication that the eBooks from the World Library are\\nsufficiently different from known public domain sources to warrant a\\nseparate copyright based on new authorship.  Digitization, markup and\\nrelated activities are not authorship.  Therefore, it is the opinion\\nof Project Gutenberg that this eBook is in the public domain in the\\nU.S. based on there being no modern authorship that would be eligible\\nfor a new copyright.\\n\\nProject Gutenberg offers no opinion on copyright status elsewhere.\\n\\nA search of the U.S. Patent and Trademark Office in December 2017\\ndid not indicate current trademark registry for \"World Library\" or\\n\"Library of the Future.\"\\n\\nFor its historical value, the original copyright statement and\\ninformation about Project Gutenberg is included here.\\n\\n\\n\"THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\\nSHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\\nPROVIDED BY PROJECT GUTENBERG ETEXT OF CARNEGIE MELLON UNIVERSITY\\nWITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\\nDISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\\nPERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\\nCOMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\\nSERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.\"\\n\\n\\n* END CONTENT NOTE *\\n\\n\\n\\n\\nEnd of Project Gutenberg’s The Complete Works of William\\nShakespeare, by William Shakespeare\\n\\n*** END OF THIS PROJECT GUTENBERG EBOOK THE COMPLETE WORKS OF WILLIAM\\nSHAKESPEARE ***\\n\\n***** This file should be named 100-0.txt or 100-0.zip ***** This and\\nall associated files of various formats will be found in:\\nhttp://www.gutenberg.org/1/0/100/\\n\\nUpdated editions will replace the previous one--the old editions will be\\nrenamed.\\n\\nCreating the works from print editions not protected by U.S. copyright\\nlaw means that no one owns a United States copyright in these works, so\\nthe Foundation (and you!) can copy and distribute it in the United\\nStates without permission and without paying copyright royalties.\\nSpecial rules, set forth in the General Terms of Use part of this\\nlicense, apply to copying and distributing Project Gutenberg-tm\\nelectronic works to protect the PROJECT GUTENBERG-tm concept and\\ntrademark. Project Gutenberg is a registered trademark, and may not be\\nused if you charge for the eBooks, unless you receive specific\\npermission. If you do not charge anything for copies of this eBook,\\ncomplying with the rules is very easy. You may use this eBook for nearly\\nany purpose such as creation of derivative works, reports, performances\\nand research. They may be modified and printed and given away--you may\\ndo practically ANYTHING in the United States with eBooks not protected\\nby U.S. copyright law. Redistribution is subject to the trademark\\nlicense, especially commercial redistribution.\\n\\nSTART: FULL LICENSE\\n\\nTHE FULL PROJECT GUTENBERG LICENSE PLEASE READ THIS BEFORE YOU\\nDISTRIBUTE OR USE THIS WORK\\n\\nTo protect the Project Gutenberg-tm mission of promoting the free\\ndistribution of electronic works, by using or distributing this work (or\\nany other work associated in any way with the phrase \"Project\\nGutenberg\"), you agree to comply with all the terms of the Full Project\\nGutenberg-tm License available with this file or online at\\nwww.gutenberg.org/license.\\n\\nSection 1. General Terms of Use and Redistributing Project Gutenberg-tm\\nelectronic works\\n\\n1.A. By reading or using any part of this Project Gutenberg-tm\\nelectronic work, you indicate that you have read, understand, agree to\\nand accept all the terms of this license and intellectual property\\n(trademark/copyright) agreement. If you do not agree to abide by all the\\nterms of this agreement, you must cease using and return or destroy all\\ncopies of Project Gutenberg-tm electronic works in your possession. If\\nyou paid a fee for obtaining a copy of or access to a Project\\nGutenberg-tm electronic work and you do not agree to be bound by the\\nterms of this agreement, you may obtain a refund from the person or\\nentity to whom you paid the fee as set forth in paragraph 1.E.8.\\n\\n1.B. \"Project Gutenberg\" is a registered trademark. It may only be used\\non or associated in any way with an electronic work by people who agree\\nto be bound by the terms of this agreement. There are a few things that\\nyou can do with most Project Gutenberg-tm electronic works even without\\ncomplying with the full terms of this agreement. See paragraph 1.C\\nbelow. There are a lot of things you can do with Project Gutenberg-tm\\nelectronic works if you follow the terms of this agreement and help\\npreserve free future access to Project Gutenberg-tm electronic works.\\nSee paragraph 1.E below.\\n\\n1.C. The Project Gutenberg Literary Archive Foundation (\"the Foundation\"\\nor PGLAF), owns a compilation copyright in the collection of Project\\nGutenberg-tm electronic works. Nearly all the individual works in the\\ncollection are in the public domain in the United States. If an\\nindividual work is unprotected by copyright law in the United States and\\nyou are located in the United States, we do not claim a right to prevent\\nyou from copying, distributing, performing, displaying or creating\\nderivative works based on the work as long as all references to Project\\nGutenberg are removed. Of course, we hope that you will support the\\nProject Gutenberg-tm mission of promoting free access to electronic\\nworks by freely sharing Project Gutenberg-tm works in compliance with\\nthe terms of this agreement for keeping the Project Gutenberg-tm name\\nassociated with the work. You can easily comply with the terms of this\\nagreement by keeping this work in the same format with its attached full\\nProject Gutenberg-tm License when you share it without charge with\\nothers.\\n\\n1.D. The copyright laws of the place where you are located also govern\\nwhat you can do with this work. Copyright laws in most countries are in\\na constant state of change. If you are outside the United States, check\\nthe laws of your country in addition to the terms of this agreement\\nbefore downloading, copying, displaying, performing, distributing or\\ncreating derivative works based on this work or any other Project\\nGutenberg-tm work. The Foundation makes no representations concerning\\nthe copyright status of any work in any country outside the United\\nStates.\\n\\n1.E. Unless you have removed all references to Project Gutenberg:\\n\\n1.E.1. The following sentence, with active links to, or other immediate\\naccess to, the full Project Gutenberg-tm License must appear prominently\\nwhenever any copy of a Project Gutenberg-tm work (any work on which the\\nphrase \"Project Gutenberg\" appears, or with which the phrase \"Project\\nGutenberg\" is associated) is accessed, displayed, performed, viewed,\\ncopied or distributed:\\n\\n  This eBook is for the use of anyone anywhere in the United States and\\n  most other parts of the world at no cost and with almost no\\n  restrictions whatsoever. You may copy it, give it away or re-use it\\n  under the terms of the Project Gutenberg License included with this\\n  eBook or online at www.gutenberg.org. If you are not located in the\\n  United States, you’ll have to check the laws of the country where you\\n  are located before using this ebook.\\n\\n1.E.2. If an individual Project Gutenberg-tm electronic work is derived\\nfrom texts not protected by U.S. copyright law (does not contain a\\nnotice indicating that it is posted with permission of the copyright\\nholder), the work can be copied and distributed to anyone in the United\\nStates without paying any fees or charges. If you are redistributing or\\nproviding access to a work with the phrase \"Project Gutenberg\"\\nassociated with or appearing on the work, you must comply either with\\nthe requirements of paragraphs 1.E.1 through 1.E.7 or obtain permission\\nfor the use of the work and the Project Gutenberg-tm trademark as set\\nforth in paragraphs 1.E.8 or 1.E.9.\\n\\n1.E.3. If an individual Project Gutenberg-tm electronic work is posted\\nwith the permission of the copyright holder, your use and distribution\\nmust comply with both paragraphs 1.E.1 through 1.E.7 and any additional\\nterms imposed by the copyright holder. Additional terms will be linked\\nto the Project Gutenberg-tm License for all works posted with the\\npermission of the copyright holder found at the beginning of this work.\\n\\n1.E.4. Do not unlink or detach or remove the full Project Gutenberg-tm\\nLicense terms from this work, or any files containing a part of this\\nwork or any other work associated with Project Gutenberg-tm.\\n\\n1.E.5. Do not copy, display, perform, distribute or redistribute this\\nelectronic work, or any part of this electronic work, without\\nprominently displaying the sentence set forth in paragraph 1.E.1 with\\nactive links or immediate access to the full terms of the Project\\nGutenberg-tm License.\\n\\n1.E.6. You may convert to and distribute this work in any binary,\\ncompressed, marked up, nonproprietary or proprietary form, including any\\nword processing or hypertext form. However, if you provide access to or\\ndistribute copies of a Project Gutenberg-tm work in a format other than\\n\"Plain Vanilla ASCII\" or other format used in the official version\\nposted on the official Project Gutenberg-tm web site\\n(www.gutenberg.org), you must, at no additional cost, fee or expense to\\nthe user, provide a copy, a means of exporting a copy, or a means of\\nobtaining a copy upon request, of the work in its original \"Plain\\nVanilla ASCII\" or other form. Any alternate format must include the full\\nProject Gutenberg-tm License as specified in paragraph 1.E.1.\\n\\n1.E.7. Do not charge a fee for access to, viewing, displaying,\\nperforming, copying or distributing any Project Gutenberg-tm works\\nunless you comply with paragraph 1.E.8 or 1.E.9.\\n\\n1.E.8. You may charge a reasonable fee for copies of or providing access\\nto or distributing Project Gutenberg-tm electronic works provided that\\n\\n* You pay a royalty fee of 20% of the gross profits you derive from the\\nuse of Project Gutenberg-tm works calculated using the method you\\nalready use to calculate your applicable taxes. The fee is owed to the\\nowner of the Project Gutenberg-tm trademark, but he has agreed to donate\\nroyalties under this paragraph to the Project Gutenberg Literary Archive\\nFoundation. Royalty payments must be paid within 60 days following each\\ndate on which you prepare (or are legally required to prepare) your\\nperiodic tax returns. Royalty payments should be clearly marked as such\\nand sent to the Project Gutenberg Literary Archive Foundation at the\\naddress specified in Section 4, \"Information about donations to the\\nProject Gutenberg Literary Archive Foundation.\"\\n\\n* You provide a full refund of any money paid by a user who notifies you\\nin writing (or by e-mail) within 30 days of receipt that s/he does not\\nagree to the terms of the full Project Gutenberg-tm License. You must\\nrequire such a user to return or destroy all copies of the works\\npossessed in a physical medium and discontinue all use of and all access\\nto other copies of Project Gutenberg-tm works.\\n\\n* You provide, in accordance with paragraph 1.F.3, a full refund of any\\nmoney paid for a work or a replacement copy, if a defect in the\\nelectronic work is discovered and reported to you within 90 days of\\nreceipt of the work.\\n\\n* You comply with all other terms of this agreement for free\\ndistribution of Project Gutenberg-tm works.\\n\\n1.E.9. If you wish to charge a fee or distribute a Project Gutenberg-tm\\nelectronic work or group of works on different terms than are set forth\\nin this agreement, you must obtain permission in writing from both the\\nProject Gutenberg Literary Archive Foundation and The Project Gutenberg\\nTrademark LLC, the owner of the Project Gutenberg-tm trademark. Contact\\nthe Foundation as set forth in Section 3 below.\\n\\n1.F.\\n\\n1.F.1. Project Gutenberg volunteers and employees expend considerable\\neffort to identify, do copyright research on, transcribe and proofread\\nworks not protected by U.S. copyright law in creating the Project\\nGutenberg-tm collection. Despite these efforts, Project Gutenberg-tm\\nelectronic works, and the medium on which they may be stored, may\\ncontain \"Defects,\" such as, but not limited to, incomplete, inaccurate\\nor corrupt data, transcription errors, a copyright or other intellectual\\nproperty infringement, a defective or damaged disk or other medium, a\\ncomputer virus, or computer codes that damage or cannot be read by your\\nequipment.\\n\\n1.F.2. LIMITED WARRANTY, DISCLAIMER OF DAMAGES - Except for the \"Right\\nof Replacement or Refund\" described in paragraph 1.F.3, the Project\\nGutenberg Literary Archive Foundation, the owner of the Project\\nGutenberg-tm trademark, and any other party distributing a Project\\nGutenberg-tm electronic work under this agreement, disclaim all\\nliability to you for damages, costs and expenses, including legal fees.\\nYOU AGREE THAT YOU HAVE NO REMEDIES FOR NEGLIGENCE, STRICT LIABILITY,\\nBREACH OF WARRANTY OR BREACH OF CONTRACT EXCEPT THOSE PROVIDED IN\\nPARAGRAPH 1.F.3. YOU AGREE THAT THE FOUNDATION, THE TRADEMARK OWNER, AND\\nANY DISTRIBUTOR UNDER THIS AGREEMENT WILL NOT BE LIABLE TO YOU FOR\\nACTUAL, DIRECT, INDIRECT, CONSEQUENTIAL, PUNITIVE OR INCIDENTAL DAMAGES\\nEVEN IF YOU GIVE NOTICE OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\n1.F.3. LIMITED RIGHT OF REPLACEMENT OR REFUND - If you discover a defect\\nin this electronic work within 90 days of receiving it, you can receive\\na refund of the money (if any) you paid for it by sending a written\\nexplanation to the person you received the work from. If you received\\nthe work on a physical medium, you must return the medium with your\\nwritten explanation. The person or entity that provided you with the\\ndefective work may elect to provide a replacement copy in lieu of a\\nrefund. If you received the work electronically, the person or entity\\nproviding it to you may choose to give you a second opportunity to\\nreceive the work electronically in lieu of a refund. If the second copy\\nis also defective, you may demand a refund in writing without further\\nopportunities to fix the problem.\\n\\n1.F.4. Except for the limited right of replacement or refund set forth\\nin paragraph 1.F.3, this work is provided to you ’AS-IS’, WITH NO\\nOTHER\\nWARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO\\nWARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PURPOSE.\\n\\n1.F.5. Some states do not allow disclaimers of certain implied\\nwarranties or the exclusion or limitation of certain types of damages.\\nIf any disclaimer or limitation set forth in this agreement violates the\\nlaw of the state applicable to this agreement, the agreement shall be\\ninterpreted to make the maximum disclaimer or limitation permitted by\\nthe applicable state law. The invalidity or unenforceability of any\\nprovision of this agreement shall not void the remaining provisions.\\n\\n1.F.6. INDEMNITY - You agree to indemnify and hold the Foundation, the\\ntrademark owner, any agent or employee of the Foundation, anyone\\nproviding copies of Project Gutenberg-tm electronic works in accordance\\nwith this agreement, and any volunteers associated with the production,\\npromotion and distribution of Project Gutenberg-tm electronic works,\\nharmless from all liability, costs and expenses, including legal fees,\\nthat arise directly or indirectly from any of the following which you do\\nor cause to occur: (a) distribution of this or any Project Gutenberg-tm\\nwork, (b) alteration, modification, or additions or deletions to any\\nProject Gutenberg-tm work, and (c) any Defect you cause.\\n\\nSection 2. Information about the Mission of Project Gutenberg-tm\\n\\nProject Gutenberg-tm is synonymous with the free distribution of\\nelectronic works in formats readable by the widest variety of computers\\nincluding obsolete, old, middle-aged and new computers. It exists\\nbecause of the efforts of hundreds of volunteers and donations from\\npeople in all walks of life.\\n\\nVolunteers and financial support to provide volunteers with the\\nassistance they need are critical to reaching Project Gutenberg-tm’s\\ngoals and ensuring that the Project Gutenberg-tm collection will remain\\nfreely available for generations to come. In 2001, the Project Gutenberg\\nLiterary Archive Foundation was created to provide a secure and\\npermanent future for Project Gutenberg-tm and future generations. To\\nlearn more about the Project Gutenberg Literary Archive Foundation and\\nhow your efforts and donations can help, see Sections 3 and 4 and the\\nFoundation information page at www.gutenberg.org Section 3. Information\\nabout the Project Gutenberg Literary Archive Foundation\\n\\nThe Project Gutenberg Literary Archive Foundation is a non profit\\n501(c)(3) educational corporation organized under the laws of the state\\nof Mississippi and granted tax exempt status by the Internal Revenue\\nService. The Foundation’s EIN or federal tax identification number is\\n64-6221541. Contributions to the Project Gutenberg Literary Archive\\nFoundation are tax deductible to the full extent permitted by U.S.\\nfederal laws and your state’s laws.\\n\\nThe Foundation’s principal office is in Fairbanks, Alaska, with the\\nmailing address: PO Box 750175, Fairbanks, AK 99775, but its volunteers\\nand employees are scattered throughout numerous locations. Its business\\noffice is located at 809 North 1500 West, Salt Lake City, UT 84116,\\n(801) 596-1887. Email contact links and up to date contact information\\ncan be found at the Foundation’s web site and official page at\\nwww.gutenberg.org/contact\\n\\nFor additional contact information:\\n\\n    Dr. Gregory B. Newby Chief Executive and Director gbnewby@pglaf.org\\n\\nSection 4. Information about Donations to the Project Gutenberg Literary\\nArchive Foundation\\n\\nProject Gutenberg-tm depends upon and cannot survive without wide spread\\npublic support and donations to carry out its mission of increasing the\\nnumber of public domain and licensed works that can be freely\\ndistributed in machine readable form accessible by the widest array of\\nequipment including outdated equipment. Many small donations ($1 to\\n$5,000) are particularly important to maintaining tax exempt status with\\nthe IRS.\\n\\nThe Foundation is committed to complying with the laws regulating\\ncharities and charitable donations in all 50 states of the United\\nStates. Compliance requirements are not uniform and it takes a\\nconsiderable effort, much paperwork and many fees to meet and keep up\\nwith these requirements. We do not solicit donations in locations where\\nwe have not received written confirmation of compliance. To SEND\\nDONATIONS or determine the status of compliance for any particular state\\nvisit www.gutenberg.org/donate\\n\\nWhile we cannot and do not solicit contributions from states where we\\nhave not met the solicitation requirements, we know of no prohibition\\nagainst accepting unsolicited donations from donors in such states who\\napproach us with offers to donate.\\n\\nInternational donations are gratefully accepted, but we cannot make any\\nstatements concerning tax treatment of donations received from outside\\nthe United States. U.S. laws alone swamp our small staff.\\n\\nPlease check the Project Gutenberg Web pages for current donation\\nmethods and addresses. Donations are accepted in a number of other ways\\nincluding checks, online payments and credit card donations. To donate,\\nplease visit: www.gutenberg.org/donate\\n\\nSection 5. General Information About Project Gutenberg-tm electronic\\nworks.\\n\\nProfessor Michael S. Hart was the originator of the Project Gutenberg-tm\\nconcept of a library of electronic works that could be freely shared\\nwith anyone. For forty years, he produced and distributed Project\\nGutenberg-tm eBooks with only a loose network of volunteer support.\\n\\nProject Gutenberg-tm eBooks are often created from several printed\\neditions, all of which are confirmed as not protected by copyright in\\nthe U.S. unless a copyright notice is included. Thus, we do not\\nnecessarily keep eBooks in compliance with any particular paper edition.\\n\\nMost people start at our Web site which has the main PG search facility:\\nwww.gutenberg.org\\n\\nThis Web site includes information about Project Gutenberg-tm, including\\nhow to make donations to the Project Gutenberg Literary Archive\\nFoundation, how to help produce our new eBooks, and how to subscribe to\\nour email newsletter to hear about new eBooks.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yhfOUq_03ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76e95b40-4598-488b-8bd6-313d248342c5"
      },
      "source": [
        "text = text[:-21100]\n",
        "\n",
        "# new end of the file\n",
        "text[-100:]"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' their course to Paphos, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n\\n\\n  FINIS\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CNUd2hB6Bdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa774edb-77b5-4229-ff48-d62009f91f49"
      },
      "source": [
        "# I also should have changed to lower case\n",
        "text = text.lower()\n",
        "text[:100]"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the complete works of william shakespeare\\n\\n\\n\\nby william shakespeare\\n\\n\\n\\n\\n      contents\\n\\n\\n\\n          '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_EOMttvjVMb",
        "colab_type": "text"
      },
      "source": [
        "### Separate text by words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak7_7iwyxpac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c28cc58c-7b19-4c4b-f879-3afa10a384ec"
      },
      "source": [
        "temp = text.replace('\\n', ' ').split(' ')\n",
        "temp[:20]"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'complete',\n",
              " 'works',\n",
              " 'of',\n",
              " 'william',\n",
              " 'shakespeare',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'by',\n",
              " 'william',\n",
              " 'shakespeare',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-kJLUI5ys9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "628b1f53-2c12-43d4-bd8b-ebdb8aacefa8"
      },
      "source": [
        "temp = list(filter(lambda a: a != '', temp))  # remove empty tokens\n",
        "temp[:20]"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'complete',\n",
              " 'works',\n",
              " 'of',\n",
              " 'william',\n",
              " 'shakespeare',\n",
              " 'by',\n",
              " 'william',\n",
              " 'shakespeare',\n",
              " 'contents',\n",
              " 'the',\n",
              " 'sonnets',\n",
              " 'all’s',\n",
              " 'well',\n",
              " 'that',\n",
              " 'ends',\n",
              " 'well',\n",
              " 'the',\n",
              " 'tragedy',\n",
              " 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqCSLuvijuK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8b543f3-6fde-4e1f-84ff-096321b55438"
      },
      "source": [
        "# break the text up into chunks of words\n",
        "\n",
        "chunk_length = 20  # words in each chunk\n",
        "w = 0\n",
        "words = []\n",
        "\n",
        "while w < len(temp):\n",
        "  chunk = []\n",
        "  for i in range(chunk_length):\n",
        "    chunk.append(temp[w])\n",
        "    w += 1\n",
        "    if w >= len(temp):\n",
        "      break\n",
        "  words.append(' '.join(chunk))\n",
        "\n",
        "print(f\"Text separated into {len(words)} chunks of {chunk_length} words each\")"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text separated into 47891 chunks of 20 words each\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJbSS3BGmXw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ae9a11a7-a818-493b-820f-229f95c1c0d2"
      },
      "source": [
        "words[:5]"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the complete works of william shakespeare by william shakespeare contents the sonnets all’s well that ends well the tragedy of',\n",
              " 'antony and cleopatra as you like it the comedy of errors the tragedy of coriolanus cymbeline the tragedy of hamlet,',\n",
              " 'prince of denmark the first part of king henry the fourth the second part of king henry the fourth the',\n",
              " 'life of king henry the fifth the first part of henry the sixth the second part of king henry the',\n",
              " 'sixth the third part of king henry the sixth king henry the eighth king john the tragedy of julius caesar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LxZdg9dzh3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cd8d2c56-235b-414d-ed95-12378c5cf8b7"
      },
      "source": [
        "words[-5:]"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['right: 1184 lo in this hollow cradle take thy rest, my throbbing heart shall rock thee day and night: there',\n",
              " 'shall not be one minute in an hour wherein i will not kiss my sweet love’s flower.” thus weary of',\n",
              " 'the world, away she hies, 1189 and yokes her silver doves; by whose swift aid their mistress mounted through the',\n",
              " 'empty skies, in her light chariot quickly is convey’d; 1192 holding their course to paphos, where their queen means to',\n",
              " 'immure herself and not be seen. finis']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkhadT3x1J4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove that last chunk to keep all of them the same length\n",
        "words = words[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8jLa2tXnXmh",
        "colab_type": "text"
      },
      "source": [
        "### Using gensim's Dictionary structure to encode those words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrQS24lPmwpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import corpora\n",
        "\n",
        "# needs an array of tokens, which I had in temp\n",
        "id2word = corpora.Dictionary([temp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6rak34N2C2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc4d8ae9-25d8-4216-d46a-24eaed778bbb"
      },
      "source": [
        "# number of unique words found\n",
        "len(id2word)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLmG-HQm4ORY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode each chunk as a list of word id's\n",
        "def encode_chunk(chunk):\n",
        "  encoded = []\n",
        "  for word in chunk.split(' '):\n",
        "    encoded.append(id2word.token2id[word])\n",
        "  return encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTSYh06S8Pu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d4a6c92c-62ab-4100-830a-d18239697554"
      },
      "source": [
        "encoded_chunks = []\n",
        "for chunk in words:\n",
        "  encoded_chunks.append(encode_chunk(chunk))\n",
        "\n",
        "encoded_chunks[0]"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[58313,\n",
              " 12814,\n",
              " 65990,\n",
              " 40789,\n",
              " 65248,\n",
              " 51934,\n",
              " 9615,\n",
              " 65248,\n",
              " 51934,\n",
              " 13600,\n",
              " 58313,\n",
              " 54166,\n",
              " 3388,\n",
              " 64514,\n",
              " 58273,\n",
              " 20215,\n",
              " 64514,\n",
              " 58313,\n",
              " 60009,\n",
              " 40789]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAPqf7lv67Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create X & y\n",
        "import numpy as np\n",
        "\n",
        "X = np.zeros((len(encoded_chunks), chunk_length, len(id2word)), dtype=np.bool)\n",
        "y = np.zeros((len(encoded_chunks),len(id2word)), dtype=np.bool)\n",
        "\n",
        "for i, chunk in enumerate(encoded_chunks):\n",
        "    for t, char in enumerate(chunk):\n",
        "        X[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "# X should be (47891, 20, 67394)... that's not gonna work"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5gFiv0ujYsF",
        "colab_type": "text"
      },
      "source": [
        "### Create and fit a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "238RpFFvjdBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_model = Sequential()\n",
        "word_model.add(LSTM(128, input_shape=(chunk_length, len(id2word))))\n",
        "word_model.add(Dense(len(id2word), activation='softmax'))\n",
        "\n",
        "word_model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqKkWdnyjdgL",
        "colab_type": "text"
      },
      "source": [
        "### Making predictions with this model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfEKInjEmx5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRI-BXU_jkHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-flcDqbJjgx5",
        "colab_type": "text"
      },
      "source": [
        "### Saving and loading for later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfh5_qdijjtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}